

import json
import time
import csv
from pathlib import Path
from typing import Dict, Tuple, Optional, List, Union

from collections import deque


import numpy as np

import paho.mqtt.client as mqtt



from sklearn.preprocessing import PolynomialFeatures


from sklearn.linear_model import SGDClassifier, PassiveAggressiveClassifier, Perceptron

from sklearn.linear_model import SGDClassifier



import logging




MQTT_BROKER = "localhost"
MQTT_PORT = 1883


MQTT_SENSOR_TOPIC = "sensors/+/value"   
MQTT_CONTROL_TOPIC = "control/mode"  



REQUIRED_DEVICES = ["dev1", "dev2", "dev3"]

SLOT_SIZE_SECONDS = 5

TRAIN_ROW_LIMIT = 100

CLASSES = np.array([0, 1])

METRICS_CSV_PATH = Path("metrics_log.csv")

METRICS_LOG_EVERY = 1  

SENSOR_VALUE_MIN = -1e3
SENSOR_VALUE_MAX = 1e6

ROBUST_BUFFER_MAX_ROWS = 500



N_LAGS = 7

MODEL_CONFIG = {

	"preprocess_steps": ["diffs"],
    "model_type": "linear_svm",


    "alert_config": {
        "enabled": True,
        "target_label": 1,
        "trigger_on": "prediction",   
        "method": "mqtt",             
        "mqtt_topic": "alerts/label1",
        "disabled_labels": [0],       

        "phases": ["TEST"],           
    },


}


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)



class RowBuffer:


    def __init__(self, slot_id: int):
        self.slot_id = slot_id
        self.messages: Dict[str, dict] = {}  # device_id -> data dict

    def add_message(self, device_id: str, data: dict) -> None:
        self.messages[device_id] = data

    def is_complete(self) -> bool:
        return all(d in self.messages for d in REQUIRED_DEVICES)

    def build_row(self) -> Tuple[np.ndarray, Optional[int]]:

        values = []
        label = None

        for dev in REQUIRED_DEVICES:
            msg = self.messages.get(dev)
            if msg is None:
                values.append(np.nan)
                continue

            val = msg.get("value")
            if val is None:
                values.append(np.nan)
            else:
                values.append(float(val))

            if label is None and "label" in msg and msg["label"] is not None:
                try:
                    label = int(msg["label"])
                except (TypeError, ValueError):
                    pass

        X_row = np.array(values, dtype=float)
        return X_row, label




# =============================
# Preprocessor: pipeline of preprocessing stages
# =============================

class Preprocessor:
    """
    Preprocessing pipeline:
      Supported steps:
        - "clean"  : basic cleaning (NaN, clip, etc.)

        - "diffs"  : add pairwise feature differences

        - "poly2"  : PolynomialFeatures degree 2

    """

    def __init__(self, steps: Union[str, List[str]]):
        if isinstance(steps, str):
            steps = [steps]
        self.steps: List[str] = [s.lower() for s in steps]

        self.poly: Optional[PolynomialFeatures] = None
        self.poly_initialized = False



    def _clean_basic(self, X_row: np.ndarray) -> np.ndarray:
        X = X_row.astype(float).copy()

        if np.all(np.isnan(X)):
            X[:] = 0.0
            return X

        nan_mask = np.isnan(X)
        if np.any(nan_mask):
            mean_val = np.nanmean(X)
            X[nan_mask] = mean_val

        X = np.clip(X, SENSOR_VALUE_MIN, SENSOR_VALUE_MAX)
        return X



    def _add_diffs(self, X: np.ndarray) -> np.ndarray:
        n = X.shape[0]
        if n < 2:
            return X

        diffs = []
        for i in range(n):
            for j in range(i + 1, n):
                diffs.append(X[i] - X[j])

        diffs = np.array(diffs, dtype=float)
        return np.concatenate([X, diffs])


    def _apply_poly2(self, X: np.ndarray) -> np.ndarray:
        if X.ndim == 1:
            X_2d = X.reshape(1, -1)
        else:
            X_2d = X

        if not self.poly_initialized:
            self.poly = PolynomialFeatures(degree=2, include_bias=False)
            self.poly.fit(X_2d)
            self.poly_initialized = True

        X_poly = self.poly.transform(X_2d)[0]
        return X_poly




    def transform(self, X_row: np.ndarray) -> np.ndarray:
        X = X_row.astype(float).copy()



                    
        for step in self.steps:
            s = step.lower()

            if s == "clean":
                X = self._clean_basic(X)
                continue    

            if s == "diffs":
                X = self._add_diffs(X)
                continue

            if s == "poly2":
                X = self._apply_poly2(X)
                continue




            logging.warning(f"Unknown preprocessing step: {step}")

        return X
    

# =============================
# Build classifier from model type
# =============================


def build_classifier(model_type: str):
    mt = model_type.lower()



    if mt == "linear_svm":
        return SGDClassifier(
            loss="hinge",
            learning_rate="optimal",
            random_state=0
        )




    else:
        logging.warning(f"Unknown MODEL_TYPE: {model_type}, using logistic_sgd.")
        return SGDClassifier(
            loss="log_loss",
            learning_rate="optimal",
            random_state=0
        )




# =============================
# AlertManager
# =============================

class AlertManager:

    def __init__(self, config: dict):
        self.enabled = config.get("enabled", False)
        self.target_label = config.get("target_label", 1)
        self.trigger_on = config.get("trigger_on", "prediction")
        self.method = config.get("method", "log")
        self.mqtt_topic = config.get("mqtt_topic", "alerts/label")

        self.disabled_labels = set(config.get("disabled_labels", []))

        # ÙØ§Ø²Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¢Ù„Ø§Ø±Ù… Ø¯Ø± Ø¢Ù†â€ŒÙ‡Ø§ ÙØ¹Ø§Ù„ Ø§Ø³Øª (TRAIN / TEST)
        self.phases = set(config.get("phases", ["TRAIN", "TEST"]))

        self._mqtt_client = None  # Ø¨Ø±Ø§ÛŒ publish Ø¢Ù„Ø§Ø±Ù… Ø¨Ø§ MQTT

    def _ensure_mqtt_client(self):
        if self._mqtt_client is None:
            self._mqtt_client = mqtt.Client()
            self._mqtt_client.connect(MQTT_BROKER, MQTT_PORT, keepalive=60)

    def _send_log(self, message: str):
        logging.warning(f"[ALERT] {message}")





    def _send_mqtt(self, payload: dict):
            try:
        # --- Convert numpy types to Python int ---
                if "slot_id" in payload:
                    payload["slot_id"] = int(payload["slot_id"])

                if "target_label" in payload:
                    payload["target_label"] = int(payload["target_label"])

                if payload.get("true_label") is not None:
                    payload["true_label"] = int(payload["true_label"])

                if payload.get("pred_label") is not None:
                    payload["pred_label"] = int(payload["pred_label"])

                if "timestamp" in payload:
                    payload["timestamp"] = float(payload["timestamp"])
        # -----------------------------------------

                self._ensure_mqtt_client()
                self._mqtt_client.publish(self.mqtt_topic, json.dumps(payload), qos=1)

        # ðŸ”¹ Ø§ÛŒÙ† Ø®Ø· Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù† Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯Ù† Ø¢Ù„Ø§Ø±Ù… Ø¯Ø± log:
                logging.info(f"[ALERT/MQTT] topic={self.mqtt_topic} payload={payload}")

            except Exception as e:
                logging.exception(f"Failed to publish alert via MQTT: {e}")



    def _send_email(self, payload: dict):
        if not (self.email_to and self.email_from and self.smtp_host):
            logging.warning("Email alert configured but SMTP settings incomplete.")
            return

        try:
            import smtplib
            from email.mime.text import MIMEText

            body = json.dumps(payload, indent=2)
            msg = MIMEText(body)
            msg["Subject"] = f"IoT Alert: label={self.target_label}"
            msg["From"] = self.email_from
            msg["To"] = self.email_to

            with smtplib.SMTP(self.smtp_host, self.smtp_port) as server:
                server.starttls()
                server.send_message(msg)

        except Exception as e:
            logging.exception(f"Failed to send alert email: {e}")

    def maybe_alert(
        self,
        *,
        phase: str,
        slot_id: int,
        true_label: Optional[int],
        pred_label: Optional[int],
    ) -> None:
        if not self.enabled:
            return

        if phase.upper() not in self.phases:
            return

        if true_label in self.disabled_labels or pred_label in self.disabled_labels:
            return

        trigger = False
        if self.trigger_on == "prediction" and pred_label == self.target_label:
            trigger = True
        elif self.trigger_on == "true" and true_label == self.target_label:
            trigger = True
        elif self.trigger_on == "both" and (
            (true_label == self.target_label) or (pred_label == self.target_label)
        ):
            trigger = True

        if not trigger:
            return

        payload = {
            "timestamp": time.time(),
            "phase": phase,
            "slot_id": slot_id,
            "target_label": self.target_label,
            "true_label": true_label,
            "pred_label": pred_label,
        }

        if self.method == "log":
            self._send_log(json.dumps(payload))
        elif self.method == "mqtt":
            self._send_mqtt(payload)
        elif self.method == "email":
            self._send_email(payload)
        else:
            logging.warning(f"Unknown alert method: {self.method}")

# =============================
# OnlineModelManager
# =============================

class OnlineModelManager:
    """
    Online model manager (Preprocessor + optional Scaling + Classifier) using partial_fit,
    manages TRAIN/TEST state and logs metrics.

    Scaling types detected from preprocess_steps:
      - Standardization: "standard", "scale", ...
      - Normalization:   "normalize", ...
      - Robust Scaling:  "robust", ...
    """

    def __init__(self, model_config: dict):
        preprocess_steps_cfg = model_config.get("preprocess_steps", ["clean"])
        model_type = model_config.get("model_type", "logistic_sgd")


        alert_config = model_config.get("alert_config", {"enabled": False})
        self.alert_manager = AlertManager(alert_config)

        if isinstance(preprocess_steps_cfg, str):
            preprocess_steps_cfg = [preprocess_steps_cfg]

        steps_lower = [s.lower() for s in preprocess_steps_cfg]

        steps_for_preproc = steps_lower  

        self.preproc = Preprocessor(steps_for_preproc)

        self.clf = build_classifier(model_type)
        self.model_initialized = False

        self.mode = "TRAIN"
        self.train_rows_seen = 0

        self.test_total = 0
        self.test_correct = 0

        self.ts_buffer: deque[np.ndarray] = deque(maxlen=N_LAGS)

        self._init_metrics_csv()

        logging.info(
            f"Initialized OnlineModelManager with MODEL_TYPE={model_type}, "
            f"PREPROCESS_STEPS={steps_for_preproc}") 


    def _init_metrics_csv(self) -> None:
        if not METRICS_CSV_PATH.exists():
            with METRICS_CSV_PATH.open("w", newline="", encoding="utf-8") as f:
                writer = csv.writer(f)
                writer.writerow([
                    "timestamp",
                    "phase",
                    "slot_id",
                    "row_index",
                    "label",
                    "prediction",
                    "correct",
                    "cumulative_accuracy"
                ])

    def _append_metrics(
        self,
        phase: str,
        slot_id: int,
        row_index: int,
        label: Optional[int],
        prediction: Optional[int]
    ) -> None:
        correct_flag = None
        if label is not None and prediction is not None:
            self.test_total += 1
            if prediction == label:
                self.test_correct += 1
            correct_flag = int(prediction == label)
            acc = self.test_correct / self.test_total
        else:
            acc = self.test_correct / self.test_total if self.test_total > 0 else 0.0

        with METRICS_CSV_PATH.open("a", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow([
                time.time(),
                phase,
                slot_id,
                row_index,
                label,
                prediction,
                correct_flag,
                acc
            ])


    # ---------- Time-series feature builder ----------

    def _build_timeseries_features(self, x_t: np.ndarray) -> Optional[np.ndarray]:
        """
        Use past N_LAGS rows as features for current time step.
        Feature vector: [x_{t-1}, x_{t-2}, ..., x_{t-N_LAGS}]
        If we don't have enough history yet â†’ return None.
        """
        if len(self.ts_buffer) < N_LAGS:
            # store current row and wait until buffer filled
            self.ts_buffer.append(x_t)
            return None

        # we have N_LAGS past rows
        past = list(self.ts_buffer)[-N_LAGS:]
        feat = np.concatenate(past)

        # update buffer: push current row for future steps
        self.ts_buffer.append(x_t)

        return feat




	def process_row(self, slot_id: int, X_row: np.ndarray, label: Optional[int]) -> None:
		# 1) preprocess single row (clean, diffs, minmax, ...)
		x_pre = self.preproc.transform(X_row)

		# 2) convert to time-series feature
		ts_feat = self._build_timeseries_features(x_pre)
		if ts_feat is None:
			logging.info(
				f"[Slot {slot_id}] Not enough history yet for time-series features "
				f"(need {N_LAGS} past rows)."
			)
			return

        X_2d = X_pre.reshape(1, -1)

        if self.mode == "TRAIN":
            self._train_step(slot_id, X_2d, label)
        else:
            self._test_step(slot_id, X_2d, label)

    def _train_step(self, slot_id: int, X_2d: np.ndarray, label: Optional[int]) -> None:
        if label is None:
            logging.warning("In TRAIN mode but no label provided; only scaling warm-up.")

            X_in = X_2d
            if self.model_initialized:
                y_pred = self.clf.predict(X_in)[0]
                logging.info(f"[TRAIN/no-label] Slot={slot_id} Pred={y_pred}")
            return

        X_in = X_2d

        y_arr = np.array([label])
        if not self.model_initialized:
            self.clf.partial_fit(X_in, y_arr, classes=CLASSES)
            self.model_initialized = True
            logging.info("Model initialized with first partial_fit.")
        else:
            self.clf.partial_fit(X_in, y_arr)

        y_pred = self.clf.predict(X_in)[0]
        self.train_rows_seen += 1
        logging.info(
            f"[TRAIN] row #{self.train_rows_seen} | Slot={slot_id} "
            f"true={label}, pred={y_pred}"
        )



        self.alert_manager.maybe_alert(
            phase="TRAIN",
            slot_id=slot_id,
            true_label=label,
            pred_label=y_pred,
        )

        if self.train_rows_seen % METRICS_LOG_EVERY == 0:
            self._append_metrics(
                phase="TRAIN",
                slot_id=slot_id,
                row_index=self.train_rows_seen,
                label=label,
                prediction=y_pred,
            )

        if self.train_rows_seen >= TRAIN_ROW_LIMIT:
            self.mode = "TEST"
            logging.info(
                f"TRAIN phase finished after {self.train_rows_seen} rows. "
                f"Switched to TEST mode (auto)."
            )

    def _test_step(self, slot_id: int, X_2d: np.ndarray, label: Optional[int]) -> None:
        if not self.model_initialized:
            logging.warning("Model not initialized; cannot predict.")
            return
        X_in = X_2d

        y_pred = self.clf.predict(X_in)[0]

        logging.info(f"[TEST] Slot={slot_id} pred={y_pred}, true_label={label}")



        self.alert_manager.maybe_alert(
            phase="TEST",
            slot_id=slot_id,
            true_label=label,
            pred_label=y_pred,
        )


        self._append_metrics(
            phase="TEST",
            slot_id=slot_id,
            row_index=self.train_rows_seen + self.test_total + 1,
            label=label,
            prediction=y_pred,
        )

    def set_mode(self, new_mode: str, reason: str = "") -> None:
        new_mode = new_mode.upper()
        if new_mode not in ("TRAIN", "TEST"):
            logging.warning(f"Invalid mode request: {new_mode}")
            return
        self.mode = new_mode
        logging.info(f"Mode changed to {self.mode} ({reason})")

# =============================
# Slot management
# =============================

slots: Dict[int, RowBuffer] = {}

def compute_slot_id(timestamp: float) -> int:
    return int(timestamp // SLOT_SIZE_SECONDS)

def get_or_create_row_buffer(slot_id: int) -> RowBuffer:
    if slot_id not in slots:
        slots[slot_id] = RowBuffer(slot_id)
    return slots[slot_id]

def remove_old_slots(current_slot_id: int, max_age_slots: int = 10) -> None:
    to_delete = [sid for sid in slots if sid < current_slot_id - max_age_slots]
    for sid in to_delete:
        del slots[sid]

# =============================
# MQTT callbacks
# =============================

model_manager = OnlineModelManager(MODEL_CONFIG)

def on_connect(client, userdata, flags, rc):
    if rc == 0:
        logging.info("Connected to MQTT broker.")
    else:
        logging.error(f"Failed to connect to MQTT broker. rc={rc}")

    client.subscribe(MQTT_SENSOR_TOPIC)
    logging.info(f"Subscribed to sensors topic: {MQTT_SENSOR_TOPIC}")

    client.subscribe(MQTT_CONTROL_TOPIC)
    logging.info(f"Subscribed to control topic: {MQTT_CONTROL_TOPIC}")

def on_message(client, userdata, msg):
    try:
        payload = msg.payload.decode("utf-8")

        if msg.topic == MQTT_CONTROL_TOPIC:
            mode_cmd = payload.strip().upper()
            if mode_cmd in ("TRAIN", "TEST"):
                model_manager.set_mode(mode_cmd, reason="by MQTT control/mode")
            else:
                logging.warning(f"Unknown control command on {MQTT_CONTROL_TOPIC}: {payload}")
            return

        data = json.loads(payload)

        device_id = data.get("device_id")
        if device_id is None:
            logging.warning("Received message without device_id; ignoring.")
            return

        ts = float(data.get("timestamp", time.time()))
        slot_id = compute_slot_id(ts)

        row_buffer = get_or_create_row_buffer(slot_id)
        row_buffer.add_message(device_id, data)

        remove_old_slots(slot_id)

        if row_buffer.is_complete():
            X_row, label = row_buffer.build_row()
            logging.info(
                f"[Slot {slot_id}] NEW ROW | mode={model_manager.mode} | "
                f"X={X_row}, label={label}"
            )

            model_manager.process_row(slot_id, X_row, label)

            if slot_id in slots:
                del slots[slot_id]

    except Exception as e:
        logging.exception(f"Error in on_message: {e}")

# =============================
# main
# =============================

def main():
    client = mqtt.Client()
    client.on_connect = on_connect
    client.on_message = on_message

    logging.info("Connecting to MQTT broker...")
    client.connect(MQTT_BROKER, MQTT_PORT, keepalive=60)

    logging.info("MQTT client started. Waiting for messages...")
    client.loop_forever()

if __name__ == "__main__":
    main()


