

import json
import time
import csv
from pathlib import Path
from typing import Dict, Tuple, Optional, List, Union


import numpy as np

import paho.mqtt.client as mqtt

from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import SGDClassifier, PassiveAggressiveClassifier, Perceptron

from sklearn.linear_model import SGDClassifier



import logging




MQTT_BROKER = "localhost"
MQTT_PORT = 1883


MQTT_SENSOR_TOPIC = "control/mode"   
MQTT_CONTROL_TOPIC = "sensors/+/value"  



REQUIRED_DEVICES = ["dev1", "dev2"]

SLOT_SIZE_SECONDS = 5

TRAIN_ROW_LIMIT = 100

CLASSES = np.array([0, 1])

METRICS_CSV_PATH = Path("metrics_log.csv")

METRICS_LOG_EVERY = 1  

SENSOR_VALUE_MIN = -1e3
SENSOR_VALUE_MAX = 1e6

ROBUST_BUFFER_MAX_ROWS = 500



MODEL_CONFIG = {

	"preprocess_steps": [],
    "model_type": "SGDClassifier",
}


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)



class RowBuffer:


    def __init__(self, slot_id: int):
        self.slot_id = slot_id
        self.messages: Dict[str, dict] = {}  # device_id -> data dict

    def add_message(self, device_id: str, data: dict) -> None:
        self.messages[device_id] = data

    def is_complete(self) -> bool:
        return all(d in self.messages for d in REQUIRED_DEVICES)

    def build_row(self) -> Tuple[np.ndarray, Optional[int]]:

        values = []
        label = None

        for dev in REQUIRED_DEVICES:
            msg = self.messages.get(dev)
            if msg is None:
                values.append(np.nan)
                continue

            val = msg.get("value")
            if val is None:
                values.append(np.nan)
            else:
                values.append(float(val))

            if label is None and "label" in msg and msg["label"] is not None:
                try:
                    label = int(msg["label"])
                except (TypeError, ValueError):
                    pass

        X_row = np.array(values, dtype=float)
        return X_row, label




# =============================
# Preprocessor: pipeline of preprocessing stages
# =============================

class Preprocessor:
    """
    Preprocessing pipeline:
      Supported steps:
        - "clean"  : basic cleaning (NaN, clip, etc.)
        - "diffs"  : add pairwise feature differences
        - "poly2"  : PolynomialFeatures degree 2
        - "minmax" : online Min-Max scaling
    """

    def __init__(self, steps: Union[str, List[str]]):
        if isinstance(steps, str):
            steps = [steps]
        self.steps: List[str] = [s.lower() for s in steps]

        self.poly: Optional[PolynomialFeatures] = None
        self.poly_initialized = False

        self.minmax_initialized = False
        self.min_: Optional[np.ndarray] = None
        self.max_: Optional[np.ndarray] = None

    def _clean_basic(self, X_row: np.ndarray) -> np.ndarray:
        X = X_row.astype(float).copy()

        if np.all(np.isnan(X)):
            X[:] = 0.0
            return X

        nan_mask = np.isnan(X)
        if np.any(nan_mask):
            mean_val = np.nanmean(X)
            X[nan_mask] = mean_val

        X = np.clip(X, SENSOR_VALUE_MIN, SENSOR_VALUE_MAX)
        return X

    def _add_diffs(self, X: np.ndarray) -> np.ndarray:
        n = X.shape[0]
        if n < 2:
            return X

        diffs = []
        for i in range(n):
            for j in range(i + 1, n):
                diffs.append(X[i] - X[j])

        diffs = np.array(diffs, dtype=float)
        return np.concatenate([X, diffs])

    def _apply_poly2(self, X: np.ndarray) -> np.ndarray:
        if X.ndim == 1:
            X_2d = X.reshape(1, -1)
        else:
            X_2d = X

        if not self.poly_initialized:
            self.poly = PolynomialFeatures(degree=2, include_bias=False)
            self.poly.fit(X_2d)
            self.poly_initialized = True

        X_poly = self.poly.transform(X_2d)[0]
        return X_poly

    def _minmax_scale(self, X: np.ndarray) -> np.ndarray:
        X = X.astype(float)

        if not self.minmax_initialized:
            self.min_ = X.copy()
            self.max_ = X.copy()
            self.minmax_initialized = True
        else:
            self.min_ = np.minimum(self.min_, X)
            self.max_ = np.maximum(self.max_, X)

        denom = self.max_ - self.min_
        denom[denom == 0] = 1.0

        return (X - self.min_) / denom

    def transform(self, X_row: np.ndarray) -> np.ndarray:
        X = X_row.astype(float).copy()

        scaling_step_names = {
            "scale", "standard", "standardization", "standard_scaler",
            "normalize", "normalization", "l2norm", "l2_norm",
            "robust", "robust_scaling", "robust_scale", "robust_scaler",
        }

        for step in self.steps:
            s = step.lower()
            if s == "clean":
                X = self._clean_basic(X)
            elif s == "diffs":
                X = self._add_diffs(X)
            elif s == "poly2":
                X = self._apply_poly2(X)
            elif s == "minmax":
                X = self._minmax_scale(X)
            elif s in scaling_step_names:
                logging.debug(
                    f"Step '{step}' ignored in Preprocessor "
                    f"(scaling handled in OnlineModelManager)."
                )
            else:
                logging.warning(f"Unknown preprocessing step: {step}")

        return X

# =============================
# Build classifier from model type
# =============================

	hi

def build_classifier(model_type: str):


    mt = model_type.lower()
    if mt == "logistic_sgd":
        return SGDClassifier(
            loss="log_loss",
            learning_rate="optimal",
            random_state=0
        )


    elif mt == "linear_svm":
        return SGDClassifier(
            loss="hinge",
            learning_rate="optimal",
            random_state=0
        )


    elif mt == "pa":
        return PassiveAggressiveClassifier(random_state=0)


    elif mt == "perceptron":
        return Perceptron(random_state=0)


    else:
        logging.warning(f"Unknown MODEL_TYPE: {model_type}, using logistic_sgd.")
        return SGDClassifier(
            loss="log_loss",
            learning_rate="optimal",
            random_state=0
        )


