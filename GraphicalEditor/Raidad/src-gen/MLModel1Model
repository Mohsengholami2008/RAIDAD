import numpy as np
import warnings
np.warnings = warnings
import pandas as pd
from sklearn.impute import SimpleImputer
import seaborn as sns
from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc
from sklearn.model_selection import cross_validate, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt


def read_csv(file_path):
    data = pd.read_csv(file_path, )
    return data








import logging
def fill_missing_values(data, impute_configurations):
    if not impute_configurations:
        raise ValueError("No imputation configurations provided")
    
    for config in impute_configurations:
        column_names = config.get('column_names')
        if not all(col in data.columns for col in column_names):
            logger.error(f"One or more columns not found in the data: {column_names}")
            raise KeyError(f"One or more columns missing from data: {column_names}")
            
        try:
            imputer = SimpleImputer(
                missing_values=config.get('missing_values', np.nan),
                strategy=config.get('strategy', 'mean'),
                fill_value=config.get('fill_value')
            )
            data[column_names] = imputer.fit_transform(data[column_names])
            logger.info(f"Imputed missing values in columns: {column_names}")
        except Exception as e:
            logger.error(f"An error occurred during imputation: {e}")
            raise
    return data
logger = logging.getLogger(__name__)







def one_hot_encoding(data, columns):
    return pd.get_dummies(data, columns=columns)







from sklearn.ensemble import VotingClassifier, RandomForestClassifier

def build_voting_classifier(voting_params):
    estimators = []

    # RandomForestClassifier
    rf_params = voting_params.get('random_forest', {})
    rf_estimator = ('rf', RandomForestClassifier(**rf_params))
    estimators.append(rf_estimator)



    voting = VotingClassifier(estimators, voting='hard')
    return voting


def perform_cross_validation(X, y, classifier, cv_folds, scoring_metrics):
    cv_results = cross_validate(classifier, X, y, cv=cv_folds, scoring=list(scoring_metrics.keys()), return_train_score=False)
    mean_scores = {metric: np.mean(cv_results[f'test_{metric}']) for metric in scoring_metrics}
    std_scores = {metric: np.std(cv_results[f'test_{metric}']) for metric in scoring_metrics}
    for metric_name in scoring_metrics:
        metric_scores = cv_results[f'test_{metric_name}']
        print(f'{metric_name}: {metric_scores}')
        print(f'Mean {metric_name}: {np.mean(metric_scores):.3f}, Standard Deviation: {np.std(metric_scores):.3f}')

        # Plotting scatter plot for individual scores
        plt.figure(figsize=(10, 6))
        plt.scatter(range(len(metric_scores)), metric_scores, c='blue', alpha=0.7, s=100)  
        plt.title(f'Individual {metric_name} Scores with Cross Validation')
        plt.xlabel('Iteration')
        plt.ylabel(metric_name)
        
        # khotut

        plt.axhline(mean_scores[metric_name], color='red', linestyle='--', label='Mean')  
        plt.axhline(mean_scores[metric_name] + std_scores[metric_name], color='green', linestyle=':', label='Mean + Std')  
        plt.axhline(mean_scores[metric_name] - std_scores[metric_name], color='green', linestyle=':', label='Mean - Std')  
        plt.legend()  
        
        plt.show()



    return cv_results












def process_data(data=None, impute_configurations=None, cv_folds=None, one_hot_columns=None, voting_params=None, ): 
	executed_functions = []
	model = None	

	a =['Simple_Imputer','OneHot','invalid','Voting_Classifier','Cross_Validation','invalid']

	for letter in range (len(a)):
		if a[letter] == 'Simple_Imputer': 
			data = fill_missing_values(data, impute_configurations)
			executed_functions.append('fill_missing_values')
















		if a[letter] == 'OneHot': 
			data = one_hot_encoding(data, one_hot_columns)
			executed_functions.append('one_hot_encoding')


		if a[letter] == 'Voting_Classifier':
			y = data[target_column]
			X = data.drop(columns=[target_column])       
			voting_model = build_voting_classifier(voting_params)
			executed_functions.append('Voting_Train')
		if a[letter] == 'Cross_Validation':       

			cv_results = perform_cross_validation(X, y, voting_model, cv_folds, scoring_metrics)                      
			executed_functions.append('perform_cross_validation')











	return data, executed_functions, model

if __name__ == "__main__":
    file_path = 'C:\Users\MyPC\Desktop\Deskto_1\data\archive (7)\train.csv'
    data = read_csv(file_path)














    impute_configurations = [
        {
            'column_names': ['SibSp', 'Embarked'],

       		'strategy': 'median',


        },
    ]













    one_hot_columns=['Pclass', 'Parch', 'Ticket']























    voting_params = {


        'random_forest': {

            'n_estimators': 200,
            'max_depth': 10,
            'min_samples_split': 2,
            'min_samples_leaf': 1,
            'random_state': 42

        },	
    }







    cv_folds = 5
    scoring_metrics = {
        'recall_macro': 'Recall Macro',
        'f1_macro': 'F1 Macro'
    }

    processed_data, executed_functions, model = process_data(


        data=data,

 
















 






		cv_folds=cv_folds,










        one_hot_columns=one_hot_columns,
 
















 
















 

   	 impute_configurations=impute_configurations,
		















 






        voting_params=voting_params,










		
		


    )



