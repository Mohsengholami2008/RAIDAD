import numpy as np
import warnings
np.warnings = warnings
import pandas as pd
from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc
from sklearn.model_selection import cross_validate, StratifiedKFold
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier


def read_csv(file_path):
    data = pd.read_csv(file_path, )
    return data









def scale_features(data, target_column, scaling_config):
    features_to_exclude = [target_column]
    features = data.drop(columns=features_to_exclude, axis=1, errors='ignore')
    scaled_data = data[features_to_exclude].copy()  

    for method, columns in scaling_config.items():
        scaler = None
        if columns:  
            if method == "standardization":
                scaler = StandardScaler()
            elif method == "minmax":
                scaler = MinMaxScaler()
            elif method == "robust":
                scaler = RobustScaler()
            if scaler:
                scaler.fit(data[columns])
                scaled_columns = scaler.transform(data[columns])
                scaled_data = scaled_data.join(pd.DataFrame(scaled_columns, columns=columns, index=data.index))

    for col in data.columns:
        if col not in scaled_data.columns:
            scaled_data[col] = data[col]
    
    return scaled_data









def build_KNN(KNN_params):
    KNN_model = KNeighborsClassifier(n_neighbors=KNN_params['k'])
    return KNN_model







def perform_cross_validation(X, y, classifier, cv_folds, scoring_metrics):
    cv_results = cross_validate(classifier, X, y, cv=cv_folds, scoring=list(scoring_metrics.keys()), return_train_score=False)
    mean_scores = {metric: np.mean(cv_results[f'test_{metric}']) for metric in scoring_metrics}
    std_scores = {metric: np.std(cv_results[f'test_{metric}']) for metric in scoring_metrics}
    for metric_name in scoring_metrics:
        metric_scores = cv_results[f'test_{metric_name}']
        print(f'{metric_name}: {metric_scores}')
        print(f'Mean {metric_name}: {np.mean(metric_scores):.3f}, Standard Deviation: {np.std(metric_scores):.3f}')




    return cv_results












def process_data(data=None,target_column=None, scaling_config=None, , KNN_params=None, cv_folds=None): 
	executed_functions = []
	model = None	

	a =['Standardization','Normalization','KNN','Cross_Validation','invalid']

	for letter in range (len(a)):





		if a[letter] == 'scaling_config':
			data = scale_features(data, target_column, scaling_config)
			scaling_methods = [method for method in scaling_config if method != "exclude"]
			executed_functions.extend(scaling_methods)












		if a[letter] == 'KNN':
			y = data[target_column]
			X = data.drop(columns=[target_column])	
     

			KNN_model = build_KNN(KNN_params)
			executed_functions.append('train_KNN')

		if a[letter] == 'Cross_Validation':       

			cv_results = perform_cross_validation(X, y, KNN_model, cv_folds, scoring_metrics)                      
			executed_functions.append('perform_cross_validation')


















	return data, executed_functions, model

if __name__ == "__main__":
    file_path = 'C:\Users\ShemrounShop\Desktop\datasets\IRIS\Iris.csv'
    data = read_csv(file_path)
    data = data.drop(columns=['Id'])















    scaling_config = {

		'standardization': ['SepalLengthCm', 'PetalLengthCm'],

		'minmax': ['SepalWidthCm'],


}













    KNN_params = {
        'k': 4
            }
























    cv_folds = 5
    scoring_metrics = {
	    'accuracy': 'Accuracy',
        'recall_macro': 'Recall Macro',
        'f1_macro': 'F1 Macro'
    }

    processed_data, executed_functions, model = process_data(


        data=data,

 
        target_column='Species',
















 






		cv_folds=cv_folds,










 


        KNN_params=KNN_params,















 
















 







        scaling_config=scaling_config,
		









		
		


    )



